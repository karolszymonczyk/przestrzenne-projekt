{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_embedding = pd.read_json('../../data/embedded_train.jl', lines=True)\n",
    "# df_embedding = pd.read_json('../../data/embedded_train_clean.jl', lines=True)\n",
    "df_embedding.loc[df_embedding[\"target\"] == \"NA\", [\"target\"]] = 0  # added\n",
    "\n",
    "df_embedding['target'] = df_embedding['target'].astype(str)\n",
    "df_embedding = df_embedding.rename(columns={'id':'id_str'})\n",
    "df_embedding['id_str'] = df_embedding['id_str'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df_embedding[\"target\"])\n",
    "df_embedding[\"target_label\"] = df_embedding[\"target\"].apply(lambda x: le.transform([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-1': 0, '0': 1, '1': 2}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "\n",
    "print(dict(zip(le.classes_, range(len(le.classes_)))))\n",
    "df_embedding[\"target_label\"].value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4a8ff3b57d54bab9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4a8ff3b57d54bab9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8088;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir lightning_logs/ --port 8088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "class TweetsDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_path: str=\"../../data\", test_size: float=0.2, batch_size: int=128):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.test_size = test_size\n",
    "        self.batch_size = batch_size\n",
    "        self.sample_map = None\n",
    "        self.le = LabelEncoder()\n",
    "        self.ss = StandardScaler()\n",
    "        # self.pca = PCA(213)  # compress to 213 features explaining 98% variance\n",
    "        # self.pca = PCA(173)  # compress to 173 features explaining 95% variance\n",
    "\n",
    "\n",
    "    def process_data(self, data):\n",
    "        self.le.fit(data[\"target\"])\n",
    "        y = data[\"target\"].apply(lambda x: self.le.transform([x])[0])\n",
    "\n",
    "        X = pd.DataFrame(data[\"embedding\"].tolist())\n",
    "        X = self.ss.fit_transform(X)\n",
    "        X = pd.concat([pd.DataFrame(X), data[\"id_str\"]], axis=1)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def calc_sample_map(self, data):\n",
    "        self.sample_map = {idx: sample_id for idx, sample_id in enumerate(data[\"id_str\"].values.tolist())}\n",
    "        return data.drop(\"id_str\", axis=1)\n",
    "\n",
    "\n",
    "    def format_data(self, data):\n",
    "        return torch.from_numpy(np.vstack(data)).float()\n",
    "\n",
    "\n",
    "    def make_pca(self, train, test):\n",
    "        # self.pca.fit(train)\n",
    "        # train = self.pca.transform(train)\n",
    "        # test = self.pca.transform(test)\n",
    "\n",
    "        train = pd.DataFrame(train).values.tolist()\n",
    "        test = pd.DataFrame(test).values.tolist()\n",
    "\n",
    "        return train, test\n",
    "\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        data = pd.read_json(self.data_path, lines=True)\n",
    "        data.loc[df_embedding[\"target\"] == \"NA\", [\"target\"]] = 0  # added\n",
    "\n",
    "        # added for new data\n",
    "        data['target'] = df_embedding['target'].astype(str)\n",
    "        data = df_embedding.rename(columns={'id':'id_str'})\n",
    "        data['id_str'] = df_embedding['id_str'].astype(str)\n",
    "\n",
    "        X, y = self.process_data(data)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "        X_train = self.calc_sample_map(X_train)\n",
    "        X_test = X_test.drop(\"id_str\", axis=1)\n",
    "\n",
    "        X_train, X_test = self.make_pca(X_train, X_test)\n",
    "        self.X_train = self.format_data(X_train)\n",
    "        self.X_test = self.format_data(X_test)\n",
    "        self.y_train = self.format_data(y_train)\n",
    "        self.y_test = self.format_data(y_test)\n",
    "        \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(TensorDataset(self.X_train, self.y_train), batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(TensorDataset(self.X_test, self.y_test), batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(TensorDataset(self.X_test, self.y_test), batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(TensorDataset(self.X_test, self.y_test), batch_size=self.batch_size)\n",
    "\n",
    "    def get_test_sets(self):\n",
    "        return self.X_test, self.y_test\n",
    "\n",
    "    def get_batch_size(self):\n",
    "        return self.batch_size\n",
    "    \n",
    "    def get_label_encoder(self):\n",
    "        return self.le\n",
    "\n",
    "    def get_sample_map(self):\n",
    "        return self.sample_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MLP(pl.LightningModule):\n",
    "  \n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, lr=1e-4):\n",
    "    super().__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.lr = lr\n",
    "    \n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      # nn.Linear(hidden_dim, hidden_dim),\n",
    "      # nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, out_features=output_dim),\n",
    "      nn.Softmax(dim=1)\n",
    "    )\n",
    "    self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "  \n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y = y.flatten().type(torch.LongTensor)\n",
    "    y_hat = self(x)\n",
    "    loss = self.loss(y_hat, y)\n",
    "    self.log('train_loss', loss, on_epoch=True, on_step=False)\n",
    "    return {\"loss\": loss, \"logits\": y_hat.detach(), \"gold\": y, \"batch_idx\": batch_idx}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y = y.flatten().type(torch.LongTensor)\n",
    "    y_hat = self(x)\n",
    "    loss = self.loss(y_hat, y)\n",
    "    y_hat = torch.argmax(self(x), 1)\n",
    "    f1 = f1_score(y.cpu(), y_hat.cpu(), average='micro')\n",
    "    acc = accuracy_score(y.cpu(), y_hat.cpu())\n",
    "    self.log(\"val_loss\", loss, prog_bar=True)\n",
    "    self.log(\"val_f1_micro\", f1, prog_bar=True)\n",
    "    self.log(\"val_acc\", acc, prog_bar=True)\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y = y.flatten().type(torch.LongTensor)\n",
    "    y_hat = self(x)\n",
    "    y_hat = torch.argmax(self(x), 1)\n",
    "\n",
    "    report = classification_report(y, y_hat, output_dict=True)\n",
    "    self.log_dict(report)\n",
    "    return report\n",
    "\n",
    "  def training_epoch_end(self, outputs):\n",
    "      batch_size = self.trainer.datamodule.get_batch_size()\n",
    "      sample_map = self.trainer.datamodule.get_sample_map()\n",
    "\n",
    "      data = {\"guid\": [], f\"logits_epoch_{self.current_epoch}\": [], \"gold\": []}\n",
    "      for batch in outputs:\n",
    "        batch_idx = batch[\"batch_idx\"]\n",
    "        curr_batch_size = len(batch[\"logits\"])\n",
    "        data[\"guid\"] += [sample_map[batch_size*batch_idx + idx] for idx in range(curr_batch_size)]\n",
    "        data[f\"logits_epoch_{self.current_epoch}\"] += batch[\"logits\"].tolist()\n",
    "        data[\"gold\"] += batch[\"gold\"].tolist()\n",
    "\n",
    "      df = pd.DataFrame(data)\n",
    "      df.to_json(f\"./training_dynamics/dynamics_epoch_{self.current_epoch}.jsonl\", lines=True, orient='records')\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "  def predict_step(\n",
    "    self,\n",
    "    batch,\n",
    "    batch_idx: int,\n",
    "    dataloader_idx: Optional[int] = None,\n",
    "  ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    x, y = batch\n",
    "    z = self(x)\n",
    "    return z, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "\n",
    "def train_model(dataloader, name, epochs=40, lr=1e-4):\n",
    "    AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "    model = MLP(\n",
    "    #   input_dim=213,  # 768\n",
    "      input_dim=768,\n",
    "      hidden_dim=768,\n",
    "      output_dim=3,  # 4\n",
    "      lr=lr\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor=\"val_loss\",\n",
    "        dirpath=\"../../data/mlp/\",\n",
    "        filename=name,\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "    )\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(\"lightning_logs/\", name=name, log_graph=True)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=epochs,\n",
    "        gpus=AVAIL_GPUS,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        logger=tb_logger,\n",
    "    )\n",
    "    trainer.fit(model, dataloader)\n",
    "\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Missing logger folder: lightning_logs/test_no_pca\n",
      "\n",
      "  | Name   | Type             | Params\n",
      "--------------------------------------------\n",
      "0 | layers | Sequential       | 592 K \n",
      "1 | loss   | CrossEntropyLoss | 0     \n",
      "--------------------------------------------\n",
      "592 K     Trainable params\n",
      "0         Non-trainable params\n",
      "592 K     Total params\n",
      "2.372     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 79/79 [00:01<00:00, 47.76it/s, loss=0.622, v_num=0, val_loss=0.852, val_f1_micro=0.678, val_acc=0.678]\n"
     ]
    }
   ],
   "source": [
    "# data = TweetsDataModule(data_path='../../data/embedded_train.jl', batch_size=32)\n",
    "# data = TweetsDataModule(data_path='../../data/embedded_train_150.jl', batch_size=32)\n",
    "data = TweetsDataModule(data_path='../../data/embedded_train_150.jl', batch_size=32)\n",
    "\n",
    "# data = TweetsDataModule(data_path='../../data/embedded_train_clean.jl', batch_size=32)\n",
    "# trainer = train_model(data, 'mlp_demoji150_3c_pca_209_209_bs=32_lr-4', epochs=20, lr=1e-4)\n",
    "trainer = train_model(data, 'test_no_pca', epochs=20, lr=1e-4)\n",
    "# clear training_dynamics when changing epochs number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_count(t, val):\n",
    "    return t.tolist().count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def test_model(model, X, y, le):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X)\n",
    "    preds = torch.argmax(preds, 1)\n",
    "    # print(tf_count(preds, 0))\n",
    "\n",
    "    return classification_report(y, preds, zero_division=0, target_names=le.classes_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = TweetsDataModule(data_path='../../data/embedded_train.jl')\n",
    "# rainer.test(model=mlp, dataloaders=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.59      0.61       120\n",
      "           0       0.68      0.70      0.69       183\n",
      "           1       0.71      0.71      0.71       197\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.67      0.67      0.67       500\n",
      "weighted avg       0.68      0.68      0.68       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = data.get_test_sets()\n",
    "le = data.get_label_encoder()\n",
    "# mlp = MLP.load_from_checkpoint(checkpoint_path=f'../../data/mlp/mlp_newdata_3c_pca_213_213_bs=32_lr-4.ckpt', input_dim=213, hidden_dim=213, output_dim=3)\n",
    "mlp = MLP.load_from_checkpoint(checkpoint_path=f'../../data/mlp/test_no_pca.ckpt', input_dim=768, hidden_dim=768, output_dim=3)\n",
    "report = test_model(mlp, X_test, y_test, le)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0     239\n",
      "1.0     156\n",
      "-1.0    105\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(le.inverse_transform(np.array(y_test.flatten(), dtype='int32')))\n",
    "print(df.value_counts())\n",
    "df.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af91805feb772e5ca358e0d7e8c046b76a3384a8e0392a1e50dac8eea804f488"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('AMC': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
