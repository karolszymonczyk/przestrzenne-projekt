{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.utils import tokenize\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train = pd.read_csv('../../data/tweets_train2.tsv', sep='\\t', converters={'target': str, 'id_str': str})\n",
    "tweets_test = pd.read_csv('../../data/tweets_test2.tsv', sep='\\t', converters={'target': str, 'id_str': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_model = KeyedVectors.load_word2vec_format('../../data/language_models/wiki.multi.pl.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "  url_free = re.compile(regex).sub('', text)\n",
    "  tokens = tokenize(url_free, lowercase=True)\n",
    "  return ' '.join(list(tokens))\n",
    "\n",
    "def filter_text(model, text):\n",
    "  return len([word for word in tokenize(text, lowercase=True) if word in model]) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_train['clean_text'] = tweets_train.apply(lambda row: clean_text(row[\"full_text\"]), axis=1)\n",
    "tweets_train = tweets_train[tweets_train.apply(lambda row: filter_text(vector_model, row['clean_text']), axis=1)]\n",
    "\n",
    "tweets_test['clean_text'] = tweets_test.apply(lambda row: clean_text(row[\"full_text\"]), axis=1)\n",
    "tweets_test = tweets_test[tweets_test.apply(lambda row: filter_text(vector_model, row['clean_text']), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(model, tweets, targets):\n",
    "  embeddings = []\n",
    "  targets_final = []\n",
    "  for tweet, target in tqdm(zip(tweets, targets)):\n",
    "    words = []\n",
    "    for word in tokenize(tweet, lowercase=True):\n",
    "      if word in model:\n",
    "        vec = model.get_vector(word)\n",
    "        norm = np.linalg.norm(vec)\n",
    "        words.append(vec / norm)\n",
    "    if len(words) > 0:\n",
    "      words = np.asarray(words)\n",
    "      embeddings.append(words.mean(axis=0))\n",
    "      targets_final.append(target)\n",
    "\n",
    "  return np.asarray(embeddings), np.asarray(targets_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 4149.41it/s]\n",
      "499it [00:00, 3944.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_train = LabelEncoder()\n",
    "le_train.fit(tweets_train[\"target\"])\n",
    "targets_train = tweets_train[\"target\"].apply(lambda x: le_train.transform([x])[0])\n",
    "\n",
    "X_train, y_train = prepare(vector_model, tweets_train['clean_text'], targets_train)\n",
    "\n",
    "\n",
    "le_test = LabelEncoder()\n",
    "le_test.fit(tweets_test[\"target\"])\n",
    "targets_test = tweets_test[\"target\"].apply(lambda x: le_test.transform([x])[0])\n",
    "\n",
    "X_test, y_test = prepare(vector_model, tweets_test['clean_text'], targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(embeddings, targets, test_size=0.2, stratify=targets, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.66014\ttrain-auc:0.85798\n",
      "[1]\teval-auc:0.69002\ttrain-auc:0.90772\n",
      "[2]\teval-auc:0.71144\ttrain-auc:0.94096\n",
      "[3]\teval-auc:0.71597\ttrain-auc:0.95887\n",
      "[4]\teval-auc:0.71504\ttrain-auc:0.97179\n",
      "[5]\teval-auc:0.72220\ttrain-auc:0.97995\n",
      "[6]\teval-auc:0.72559\ttrain-auc:0.98596\n",
      "[7]\teval-auc:0.72227\ttrain-auc:0.99067\n",
      "[8]\teval-auc:0.72263\ttrain-auc:0.99361\n",
      "[9]\teval-auc:0.73205\ttrain-auc:0.99543\n",
      "[10]\teval-auc:0.73432\ttrain-auc:0.99708\n",
      "[11]\teval-auc:0.73120\ttrain-auc:0.99827\n",
      "[12]\teval-auc:0.73327\ttrain-auc:0.99883\n",
      "[13]\teval-auc:0.73786\ttrain-auc:0.99941\n",
      "[14]\teval-auc:0.73777\ttrain-auc:0.99963\n",
      "[15]\teval-auc:0.73852\ttrain-auc:0.99978\n",
      "[16]\teval-auc:0.74137\ttrain-auc:0.99984\n",
      "[17]\teval-auc:0.74157\ttrain-auc:0.99992\n",
      "[18]\teval-auc:0.74131\ttrain-auc:0.99992\n",
      "[19]\teval-auc:0.74177\ttrain-auc:0.99994\n",
      "[20]\teval-auc:0.74137\ttrain-auc:0.99996\n",
      "[21]\teval-auc:0.74213\ttrain-auc:0.99998\n",
      "[22]\teval-auc:0.74222\ttrain-auc:0.99998\n",
      "[23]\teval-auc:0.74385\ttrain-auc:0.99998\n",
      "[24]\teval-auc:0.74497\ttrain-auc:0.99999\n",
      "[25]\teval-auc:0.74499\ttrain-auc:0.99999\n",
      "[26]\teval-auc:0.74755\ttrain-auc:0.99999\n",
      "[27]\teval-auc:0.74776\ttrain-auc:1.00000\n",
      "[28]\teval-auc:0.74691\ttrain-auc:1.00000\n",
      "[29]\teval-auc:0.74506\ttrain-auc:1.00000\n",
      "[30]\teval-auc:0.74675\ttrain-auc:1.00000\n",
      "[31]\teval-auc:0.74753\ttrain-auc:1.00000\n",
      "[32]\teval-auc:0.74907\ttrain-auc:1.00000\n",
      "[33]\teval-auc:0.74900\ttrain-auc:1.00000\n",
      "[34]\teval-auc:0.74948\ttrain-auc:1.00000\n",
      "[35]\teval-auc:0.75048\ttrain-auc:1.00000\n",
      "[36]\teval-auc:0.75023\ttrain-auc:1.00000\n",
      "[37]\teval-auc:0.74911\ttrain-auc:1.00000\n",
      "[38]\teval-auc:0.74947\ttrain-auc:1.00000\n",
      "[39]\teval-auc:0.74973\ttrain-auc:1.00000\n",
      "[40]\teval-auc:0.75005\ttrain-auc:1.00000\n",
      "[41]\teval-auc:0.74979\ttrain-auc:1.00000\n",
      "[42]\teval-auc:0.75019\ttrain-auc:1.00000\n",
      "[43]\teval-auc:0.75122\ttrain-auc:1.00000\n",
      "[44]\teval-auc:0.75234\ttrain-auc:1.00000\n",
      "[45]\teval-auc:0.75166\ttrain-auc:1.00000\n",
      "[46]\teval-auc:0.75099\ttrain-auc:1.00000\n",
      "[47]\teval-auc:0.75038\ttrain-auc:1.00000\n",
      "[48]\teval-auc:0.74985\ttrain-auc:1.00000\n",
      "[49]\teval-auc:0.75109\ttrain-auc:1.00000\n",
      "[50]\teval-auc:0.75024\ttrain-auc:1.00000\n",
      "[51]\teval-auc:0.74952\ttrain-auc:1.00000\n",
      "[52]\teval-auc:0.74915\ttrain-auc:1.00000\n",
      "[53]\teval-auc:0.74933\ttrain-auc:1.00000\n",
      "[54]\teval-auc:0.74962\ttrain-auc:1.00000\n",
      "[55]\teval-auc:0.74940\ttrain-auc:1.00000\n",
      "[56]\teval-auc:0.75058\ttrain-auc:1.00000\n",
      "[57]\teval-auc:0.75011\ttrain-auc:1.00000\n",
      "[58]\teval-auc:0.75100\ttrain-auc:1.00000\n",
      "[59]\teval-auc:0.75130\ttrain-auc:1.00000\n",
      "[60]\teval-auc:0.75141\ttrain-auc:1.00000\n",
      "[61]\teval-auc:0.75175\ttrain-auc:1.00000\n",
      "[62]\teval-auc:0.75199\ttrain-auc:1.00000\n",
      "[63]\teval-auc:0.75223\ttrain-auc:1.00000\n",
      "[64]\teval-auc:0.75235\ttrain-auc:1.00000\n",
      "[65]\teval-auc:0.75262\ttrain-auc:1.00000\n",
      "[66]\teval-auc:0.75254\ttrain-auc:1.00000\n",
      "[67]\teval-auc:0.75241\ttrain-auc:1.00000\n",
      "[68]\teval-auc:0.75330\ttrain-auc:1.00000\n",
      "[69]\teval-auc:0.75254\ttrain-auc:1.00000\n",
      "[70]\teval-auc:0.75291\ttrain-auc:1.00000\n",
      "[71]\teval-auc:0.75384\ttrain-auc:1.00000\n",
      "[72]\teval-auc:0.75348\ttrain-auc:1.00000\n",
      "[73]\teval-auc:0.75375\ttrain-auc:1.00000\n",
      "[74]\teval-auc:0.75298\ttrain-auc:1.00000\n",
      "[75]\teval-auc:0.75337\ttrain-auc:1.00000\n",
      "[76]\teval-auc:0.75317\ttrain-auc:1.00000\n",
      "[77]\teval-auc:0.75344\ttrain-auc:1.00000\n",
      "[78]\teval-auc:0.75375\ttrain-auc:1.00000\n",
      "[79]\teval-auc:0.75355\ttrain-auc:1.00000\n",
      "[80]\teval-auc:0.75324\ttrain-auc:1.00000\n",
      "[81]\teval-auc:0.75320\ttrain-auc:1.00000\n",
      "[82]\teval-auc:0.75400\ttrain-auc:1.00000\n",
      "[83]\teval-auc:0.75438\ttrain-auc:1.00000\n",
      "[84]\teval-auc:0.75430\ttrain-auc:1.00000\n",
      "[85]\teval-auc:0.75439\ttrain-auc:1.00000\n",
      "[86]\teval-auc:0.75466\ttrain-auc:1.00000\n",
      "[87]\teval-auc:0.75450\ttrain-auc:1.00000\n",
      "[88]\teval-auc:0.75465\ttrain-auc:1.00000\n",
      "[89]\teval-auc:0.75460\ttrain-auc:1.00000\n",
      "[90]\teval-auc:0.75496\ttrain-auc:1.00000\n",
      "[91]\teval-auc:0.75487\ttrain-auc:1.00000\n",
      "[92]\teval-auc:0.75470\ttrain-auc:1.00000\n",
      "[93]\teval-auc:0.75470\ttrain-auc:1.00000\n",
      "[94]\teval-auc:0.75455\ttrain-auc:1.00000\n",
      "[95]\teval-auc:0.75452\ttrain-auc:1.00000\n",
      "[96]\teval-auc:0.75469\ttrain-auc:1.00000\n",
      "[97]\teval-auc:0.75489\ttrain-auc:1.00000\n",
      "[98]\teval-auc:0.75539\ttrain-auc:1.00000\n",
      "[99]\teval-auc:0.75560\ttrain-auc:1.00000\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth': 5, 'eta': 0.4, 'objective': 'multi:softprob', 'num_class': 4}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "num_round = 100\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.49      0.52       111\n",
      "           1       0.58      0.64      0.61       165\n",
      "           2       0.39      0.60      0.47       115\n",
      "           3       0.67      0.27      0.38       108\n",
      "\n",
      "    accuracy                           0.52       499\n",
      "   macro avg       0.55      0.50      0.50       499\n",
      "weighted avg       0.55      0.52      0.51       499\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_hat = bst.predict(dtest)\n",
    "\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "report = classification_report(y_test, y_hat)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = le_test.inverse_transform(y_hat)\n",
    "tweets_test['prediction'] = predicted_labels\n",
    "tweets_test['MW'] = 'NA'\n",
    "tweets_test['JP'] = 'NA'\n",
    "tweets_test['KS'] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotators_df = pd.read_csv('../../data/original_data.tsv', sep='\\t', converters={'target': str, 'id': str})\n",
    "annotators_df.loc[annotators_df['MW'].isna(), 'MW'] = 'NA'\n",
    "annotators_df.loc[annotators_df['JP'].isna(), 'JP'] = 'NA'\n",
    "annotators_df.loc[annotators_df['KS'].isna(), 'KS'] = 'NA'\n",
    "text_set = set(annotators_df['full_text'])\n",
    "\n",
    "def combine_columns(row, df, target_col):\n",
    "  if row['full_text'] in text_set:\n",
    "    return df[df['full_text'] == row['full_text']][target_col].iloc[0]\n",
    "  else:\n",
    "    return 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test['MW'] = tweets_test.apply(lambda row: combine_columns(row, annotators_df, 'MW'), axis=1)\n",
    "tweets_test['JP'] = tweets_test.apply(lambda row: combine_columns(row, annotators_df, 'JP'), axis=1)\n",
    "tweets_test['KS'] = tweets_test.apply(lambda row: combine_columns(row, annotators_df, 'KS'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test.to_csv('../../data/target_comparison.tsv', sep='\\t', index=False, columns=['id_str', 'full_text', 'target', 'prediction', 'MW', 'JP', 'KS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.95)\n",
    "pca.fit(embeddings)\n",
    "pc = pca.transform(embeddings)\n",
    "# transform test\n",
    "pca.n_components_\n",
    "# pca.explained_variance_ratio_\n",
    "\n",
    "# .98 -> 213 components\n",
    "# .95 -> 173 components\n",
    "# .90 -> 144 components\n",
    "# .80 -> 105 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(pc, targets, test_size=0.2, stratify=targets, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_pca, label=y_train_pca)\n",
    "dtest = xgb.DMatrix(X_test_pca, label=y_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.68508\ttrain-auc:0.79545\n",
      "[1]\teval-auc:0.70653\ttrain-auc:0.83425\n",
      "[2]\teval-auc:0.70715\ttrain-auc:0.85075\n",
      "[3]\teval-auc:0.70753\ttrain-auc:0.87615\n",
      "[4]\teval-auc:0.71748\ttrain-auc:0.89817\n",
      "[5]\teval-auc:0.71522\ttrain-auc:0.91128\n",
      "[6]\teval-auc:0.71982\ttrain-auc:0.92539\n",
      "[7]\teval-auc:0.72236\ttrain-auc:0.93521\n",
      "[8]\teval-auc:0.72171\ttrain-auc:0.94535\n",
      "[9]\teval-auc:0.72205\ttrain-auc:0.95535\n",
      "[10]\teval-auc:0.72137\ttrain-auc:0.96278\n",
      "[11]\teval-auc:0.72152\ttrain-auc:0.96811\n",
      "[12]\teval-auc:0.72284\ttrain-auc:0.97276\n",
      "[13]\teval-auc:0.72459\ttrain-auc:0.97666\n",
      "[14]\teval-auc:0.72522\ttrain-auc:0.98141\n",
      "[15]\teval-auc:0.72734\ttrain-auc:0.98477\n",
      "[16]\teval-auc:0.72419\ttrain-auc:0.98745\n",
      "[17]\teval-auc:0.72763\ttrain-auc:0.98962\n",
      "[18]\teval-auc:0.72738\ttrain-auc:0.99122\n",
      "[19]\teval-auc:0.72640\ttrain-auc:0.99259\n",
      "[20]\teval-auc:0.72790\ttrain-auc:0.99382\n",
      "[21]\teval-auc:0.72920\ttrain-auc:0.99513\n",
      "[22]\teval-auc:0.73054\ttrain-auc:0.99603\n",
      "[23]\teval-auc:0.72972\ttrain-auc:0.99675\n",
      "[24]\teval-auc:0.72881\ttrain-auc:0.99722\n",
      "[25]\teval-auc:0.72887\ttrain-auc:0.99775\n",
      "[26]\teval-auc:0.72865\ttrain-auc:0.99831\n",
      "[27]\teval-auc:0.72759\ttrain-auc:0.99865\n",
      "[28]\teval-auc:0.72868\ttrain-auc:0.99892\n",
      "[29]\teval-auc:0.73083\ttrain-auc:0.99908\n",
      "[30]\teval-auc:0.73184\ttrain-auc:0.99915\n",
      "[31]\teval-auc:0.73007\ttrain-auc:0.99932\n",
      "[32]\teval-auc:0.72942\ttrain-auc:0.99939\n",
      "[33]\teval-auc:0.72983\ttrain-auc:0.99948\n",
      "[34]\teval-auc:0.72952\ttrain-auc:0.99962\n",
      "[35]\teval-auc:0.73014\ttrain-auc:0.99966\n",
      "[36]\teval-auc:0.72784\ttrain-auc:0.99973\n",
      "[37]\teval-auc:0.72683\ttrain-auc:0.99976\n",
      "[38]\teval-auc:0.72818\ttrain-auc:0.99977\n",
      "[39]\teval-auc:0.72872\ttrain-auc:0.99979\n",
      "[40]\teval-auc:0.72848\ttrain-auc:0.99980\n",
      "[41]\teval-auc:0.72913\ttrain-auc:0.99981\n",
      "[42]\teval-auc:0.73135\ttrain-auc:0.99983\n",
      "[43]\teval-auc:0.73150\ttrain-auc:0.99984\n",
      "[44]\teval-auc:0.73081\ttrain-auc:0.99984\n",
      "[45]\teval-auc:0.73099\ttrain-auc:0.99986\n",
      "[46]\teval-auc:0.73085\ttrain-auc:0.99986\n",
      "[47]\teval-auc:0.72972\ttrain-auc:0.99985\n",
      "[48]\teval-auc:0.72797\ttrain-auc:0.99986\n",
      "[49]\teval-auc:0.72609\ttrain-auc:0.99987\n",
      "[50]\teval-auc:0.72730\ttrain-auc:0.99988\n",
      "[51]\teval-auc:0.72843\ttrain-auc:0.99987\n",
      "[52]\teval-auc:0.72878\ttrain-auc:0.99989\n",
      "[53]\teval-auc:0.72817\ttrain-auc:0.99989\n",
      "[54]\teval-auc:0.72802\ttrain-auc:0.99990\n",
      "[55]\teval-auc:0.72803\ttrain-auc:0.99990\n",
      "[56]\teval-auc:0.72988\ttrain-auc:0.99989\n",
      "[57]\teval-auc:0.73039\ttrain-auc:0.99991\n",
      "[58]\teval-auc:0.73058\ttrain-auc:0.99993\n",
      "[59]\teval-auc:0.73169\ttrain-auc:0.99993\n",
      "[60]\teval-auc:0.73161\ttrain-auc:0.99992\n",
      "[61]\teval-auc:0.72988\ttrain-auc:0.99993\n",
      "[62]\teval-auc:0.73017\ttrain-auc:0.99993\n",
      "[63]\teval-auc:0.72952\ttrain-auc:0.99994\n",
      "[64]\teval-auc:0.72964\ttrain-auc:0.99994\n",
      "[65]\teval-auc:0.72910\ttrain-auc:0.99995\n",
      "[66]\teval-auc:0.72895\ttrain-auc:0.99995\n",
      "[67]\teval-auc:0.72850\ttrain-auc:0.99995\n",
      "[68]\teval-auc:0.72901\ttrain-auc:0.99996\n",
      "[69]\teval-auc:0.72898\ttrain-auc:0.99996\n",
      "[70]\teval-auc:0.72956\ttrain-auc:0.99996\n",
      "[71]\teval-auc:0.72936\ttrain-auc:0.99996\n",
      "[72]\teval-auc:0.72943\ttrain-auc:0.99997\n",
      "[73]\teval-auc:0.73052\ttrain-auc:0.99996\n",
      "[74]\teval-auc:0.73051\ttrain-auc:0.99997\n",
      "[75]\teval-auc:0.72949\ttrain-auc:0.99997\n",
      "[76]\teval-auc:0.73003\ttrain-auc:0.99998\n",
      "[77]\teval-auc:0.72971\ttrain-auc:0.99998\n",
      "[78]\teval-auc:0.72932\ttrain-auc:0.99998\n",
      "[79]\teval-auc:0.73014\ttrain-auc:0.99998\n",
      "[80]\teval-auc:0.73023\ttrain-auc:0.99998\n",
      "[81]\teval-auc:0.72974\ttrain-auc:0.99999\n",
      "[82]\teval-auc:0.72863\ttrain-auc:0.99999\n",
      "[83]\teval-auc:0.72855\ttrain-auc:0.99999\n",
      "[84]\teval-auc:0.72920\ttrain-auc:0.99999\n",
      "[85]\teval-auc:0.72894\ttrain-auc:0.99999\n",
      "[86]\teval-auc:0.73011\ttrain-auc:0.99999\n",
      "[87]\teval-auc:0.72907\ttrain-auc:0.99999\n",
      "[88]\teval-auc:0.72800\ttrain-auc:0.99999\n",
      "[89]\teval-auc:0.72888\ttrain-auc:0.99999\n",
      "[90]\teval-auc:0.72938\ttrain-auc:0.99999\n",
      "[91]\teval-auc:0.72886\ttrain-auc:0.99999\n",
      "[92]\teval-auc:0.72898\ttrain-auc:0.99999\n",
      "[93]\teval-auc:0.72802\ttrain-auc:0.99999\n",
      "[94]\teval-auc:0.72869\ttrain-auc:0.99999\n",
      "[95]\teval-auc:0.72805\ttrain-auc:0.99999\n",
      "[96]\teval-auc:0.72832\ttrain-auc:0.99999\n",
      "[97]\teval-auc:0.72837\ttrain-auc:0.99999\n",
      "[98]\teval-auc:0.72744\ttrain-auc:0.99999\n",
      "[99]\teval-auc:0.72778\ttrain-auc:0.99999\n",
      "[100]\teval-auc:0.72792\ttrain-auc:0.99999\n",
      "[101]\teval-auc:0.72698\ttrain-auc:0.99999\n",
      "[102]\teval-auc:0.72710\ttrain-auc:0.99999\n",
      "[103]\teval-auc:0.72708\ttrain-auc:0.99999\n",
      "[104]\teval-auc:0.72795\ttrain-auc:0.99999\n",
      "[105]\teval-auc:0.72860\ttrain-auc:0.99999\n",
      "[106]\teval-auc:0.72867\ttrain-auc:0.99999\n",
      "[107]\teval-auc:0.72899\ttrain-auc:0.99999\n",
      "[108]\teval-auc:0.72826\ttrain-auc:0.99999\n",
      "[109]\teval-auc:0.72976\ttrain-auc:0.99999\n",
      "[110]\teval-auc:0.72986\ttrain-auc:0.99999\n",
      "[111]\teval-auc:0.72879\ttrain-auc:0.99999\n",
      "[112]\teval-auc:0.72839\ttrain-auc:0.99999\n",
      "[113]\teval-auc:0.72805\ttrain-auc:0.99999\n",
      "[114]\teval-auc:0.72766\ttrain-auc:0.99999\n",
      "[115]\teval-auc:0.72810\ttrain-auc:0.99999\n",
      "[116]\teval-auc:0.72828\ttrain-auc:0.99999\n",
      "[117]\teval-auc:0.72885\ttrain-auc:0.99999\n",
      "[118]\teval-auc:0.72850\ttrain-auc:0.99999\n",
      "[119]\teval-auc:0.72905\ttrain-auc:0.99999\n",
      "[120]\teval-auc:0.73007\ttrain-auc:0.99999\n",
      "[121]\teval-auc:0.73063\ttrain-auc:0.99999\n",
      "[122]\teval-auc:0.73086\ttrain-auc:0.99999\n",
      "[123]\teval-auc:0.73077\ttrain-auc:0.99999\n",
      "[124]\teval-auc:0.73067\ttrain-auc:0.99999\n",
      "[125]\teval-auc:0.73083\ttrain-auc:0.99999\n",
      "[126]\teval-auc:0.73096\ttrain-auc:0.99999\n",
      "[127]\teval-auc:0.73083\ttrain-auc:0.99999\n",
      "[128]\teval-auc:0.73081\ttrain-auc:0.99999\n",
      "[129]\teval-auc:0.73088\ttrain-auc:0.99999\n",
      "[130]\teval-auc:0.73078\ttrain-auc:0.99999\n",
      "[131]\teval-auc:0.73082\ttrain-auc:0.99999\n",
      "[132]\teval-auc:0.73092\ttrain-auc:0.99999\n",
      "[133]\teval-auc:0.73067\ttrain-auc:0.99999\n",
      "[134]\teval-auc:0.73085\ttrain-auc:0.99999\n",
      "[135]\teval-auc:0.73084\ttrain-auc:0.99999\n",
      "[136]\teval-auc:0.73063\ttrain-auc:0.99999\n",
      "[137]\teval-auc:0.73050\ttrain-auc:0.99999\n",
      "[138]\teval-auc:0.73020\ttrain-auc:0.99999\n",
      "[139]\teval-auc:0.72997\ttrain-auc:0.99999\n",
      "[140]\teval-auc:0.72986\ttrain-auc:0.99999\n",
      "[141]\teval-auc:0.73018\ttrain-auc:0.99999\n",
      "[142]\teval-auc:0.72970\ttrain-auc:0.99999\n",
      "[143]\teval-auc:0.72999\ttrain-auc:0.99999\n",
      "[144]\teval-auc:0.72953\ttrain-auc:0.99999\n",
      "[145]\teval-auc:0.72984\ttrain-auc:0.99999\n",
      "[146]\teval-auc:0.72961\ttrain-auc:0.99999\n",
      "[147]\teval-auc:0.72963\ttrain-auc:0.99999\n",
      "[148]\teval-auc:0.72958\ttrain-auc:0.99999\n",
      "[149]\teval-auc:0.73005\ttrain-auc:0.99999\n",
      "[150]\teval-auc:0.73017\ttrain-auc:0.99999\n",
      "[151]\teval-auc:0.73009\ttrain-auc:0.99999\n",
      "[152]\teval-auc:0.73033\ttrain-auc:0.99999\n",
      "[153]\teval-auc:0.73002\ttrain-auc:0.99999\n",
      "[154]\teval-auc:0.73042\ttrain-auc:0.99999\n",
      "[155]\teval-auc:0.73048\ttrain-auc:0.99999\n",
      "[156]\teval-auc:0.73053\ttrain-auc:0.99999\n",
      "[157]\teval-auc:0.73101\ttrain-auc:0.99999\n",
      "[158]\teval-auc:0.73108\ttrain-auc:0.99999\n",
      "[159]\teval-auc:0.73108\ttrain-auc:0.99999\n",
      "[160]\teval-auc:0.73073\ttrain-auc:0.99999\n",
      "[161]\teval-auc:0.73124\ttrain-auc:0.99999\n",
      "[162]\teval-auc:0.73082\ttrain-auc:0.99999\n",
      "[163]\teval-auc:0.73050\ttrain-auc:0.99999\n",
      "[164]\teval-auc:0.73063\ttrain-auc:0.99999\n",
      "[165]\teval-auc:0.73054\ttrain-auc:0.99999\n",
      "[166]\teval-auc:0.73042\ttrain-auc:0.99999\n",
      "[167]\teval-auc:0.73063\ttrain-auc:0.99999\n",
      "[168]\teval-auc:0.73071\ttrain-auc:0.99999\n",
      "[169]\teval-auc:0.73103\ttrain-auc:0.99999\n",
      "[170]\teval-auc:0.73130\ttrain-auc:0.99999\n",
      "[171]\teval-auc:0.73122\ttrain-auc:0.99999\n",
      "[172]\teval-auc:0.73069\ttrain-auc:0.99999\n",
      "[173]\teval-auc:0.73142\ttrain-auc:0.99999\n",
      "[174]\teval-auc:0.73139\ttrain-auc:0.99999\n",
      "[175]\teval-auc:0.73116\ttrain-auc:0.99999\n",
      "[176]\teval-auc:0.73154\ttrain-auc:0.99999\n",
      "[177]\teval-auc:0.73164\ttrain-auc:0.99999\n",
      "[178]\teval-auc:0.73162\ttrain-auc:0.99999\n",
      "[179]\teval-auc:0.73229\ttrain-auc:0.99999\n",
      "[180]\teval-auc:0.73226\ttrain-auc:0.99999\n",
      "[181]\teval-auc:0.73235\ttrain-auc:0.99999\n",
      "[182]\teval-auc:0.73199\ttrain-auc:0.99999\n",
      "[183]\teval-auc:0.73231\ttrain-auc:0.99999\n",
      "[184]\teval-auc:0.73251\ttrain-auc:0.99999\n",
      "[185]\teval-auc:0.73250\ttrain-auc:0.99999\n",
      "[186]\teval-auc:0.73284\ttrain-auc:0.99999\n",
      "[187]\teval-auc:0.73284\ttrain-auc:0.99999\n",
      "[188]\teval-auc:0.73305\ttrain-auc:0.99999\n",
      "[189]\teval-auc:0.73301\ttrain-auc:0.99999\n",
      "[190]\teval-auc:0.73324\ttrain-auc:0.99999\n",
      "[191]\teval-auc:0.73379\ttrain-auc:0.99999\n",
      "[192]\teval-auc:0.73353\ttrain-auc:0.99999\n",
      "[193]\teval-auc:0.73368\ttrain-auc:0.99999\n",
      "[194]\teval-auc:0.73350\ttrain-auc:0.99999\n",
      "[195]\teval-auc:0.73339\ttrain-auc:0.99999\n",
      "[196]\teval-auc:0.73338\ttrain-auc:0.99999\n",
      "[197]\teval-auc:0.73361\ttrain-auc:0.99999\n",
      "[198]\teval-auc:0.73442\ttrain-auc:0.99999\n",
      "[199]\teval-auc:0.73406\ttrain-auc:0.99999\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth': 4, 'eta': 0.3, 'objective': 'multi:softprob', 'num_class': 4}\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "num_round = 200\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.40      0.44       105\n",
      "           1       0.52      0.61      0.56       170\n",
      "           2       0.50      0.55      0.52       156\n",
      "           3       0.25      0.14      0.18        69\n",
      "\n",
      "    accuracy                           0.48       500\n",
      "   macro avg       0.44      0.43      0.43       500\n",
      "weighted avg       0.47      0.48      0.47       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_hat = bst.predict(dtest)\n",
    "\n",
    "y_hat = np.argmax(y_hat, axis=1)\n",
    "report = classification_report(y_test, y_hat)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3891a413c9413807c1dd9657114be1b483746a632775f2fb4ed6f769f0aee0d8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
